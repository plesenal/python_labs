import pytest
from lib.text import *


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\\n–ú–ò—Ä\\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\\r\\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected

@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        (["a", "b", "a", "c", "b", "a"], [("a", 3), ("b", 2), ("c", 1)]),
        (["bb", "aa", "bb", "aa", "cc"], [("aa", 2), ("bb", 2), ("cc", 1)]),
    ],
)
def test_count_freq_and_top_n(source, expected):
    assert top_n(count_freq(source)) == expected


def test_top_n_tie_breaker():
    assert top_n(count_freq(["bb", "aa", "bb", "aa", "cc"]), 2) == [
        ("aa", 2),
        ("bb", 2),
    ]
def test_normalize_error():
    with pytest.raises(TypeError) as excinfo:
        normalize(123)
    assert excinfo.type == TypeError
@pytest.mark.parametrize(
    "source, expected",
    [
        ('–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t' , [('–º–∏—Ä', 1), ('–ø—Ä–∏–≤–µ—Ç', 1)]),
        ('—ë–∂–∏–∫, –Å–ª–∫–∞' , [('–µ–∂–∏–∫', 1), ('–µ–ª–∫–∞', 1)]),
        ('Hello\r\nWorld' ,[('hello', 1), ('world', 1)]),
        ('  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ' , [('–¥–≤–æ–π–Ω—ã–µ', 1), ('–ø—Ä–æ–±–µ–ª—ã', 1)])
    ]
)
def test_all_for_top_basic(source, expected):
    assert all_for_top_n(source) == expected
