import re 
test1 = ["ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t","Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°","Hello\r\nWorld","  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  "]
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    text = ' '.join(text.split())
    for el in text:
        if el.isupper():
            casefold = True 
            break
        else:
            casefold = False
    if casefold:
        text = text.casefold()
    if 'Ñ‘' not in text:
        yo2e = False
    if yo2e:
        text = text.replace('Ñ‘','Ðµ')
    return text 
'''
for el in test:
    print(f"{repr(el)} -> {repr(normalize(el))}")
'''
test2 =["Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€", "hello,world!!!", "2025 Ð³Ð¾Ð´","Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾",'emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾']
def tokenize(text: str) -> list[str]:
    return re.findall(r'[Ð°-Ñ0-9-_]+',text)
'''
for el in test2:
    print(f"{repr(el)} -> {repr(tokenize(el))}")
'''
test3 = [["a","b","a","c","b","a"],["bb","aa","bb","aa","cc"]]
def count_freq(tokens: list[str]) -> dict[str, int]:
    alf = list(sorted(set(tokens)))
    chastots = {}
    for el in alf:
        chastots[el] = tokens.count(el)
    return chastots
'''
for el in test3:
    print(f"{repr(el)} -> {repr(count_freq(el))}")
'''
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    top_dict =dict(sorted(freq.items(), key=lambda item: (item[1], item[0])))
    top = list(freq.items())[:n]
    return top
for el in test3:
    print(f"Ñ‚Ð¾ÐºÐµÐ½Ñ‹ {repr(el)} -> Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ {repr(count_freq(el))} ;\nÑ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ {count_freq(el)}, n=2 -> Ñ‚Ð¾Ð¿ {top_n(count_freq(el),n = 2)}\n")